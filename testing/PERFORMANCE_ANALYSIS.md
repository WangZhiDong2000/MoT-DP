# æ¨¡å‹æ€§èƒ½åˆ†ææŠ¥å‘Š

## æ€»ä½“é—®é¢˜
- **conditional_sample æ€»è€—æ—¶**: ~2ç§’ (10æ­¥æ¨ç†)
- **å•æ­¥æ¨ç†è€—æ—¶**: ~200ms
- **ç›®æ ‡**: éœ€è¦å¤§å¹…é™ä½æ¨ç†æ—¶é—´

## è¯¦ç»†æ€§èƒ½åˆ†æ

### å•æ¬¡å‰å‘ä¼ æ’­è€—æ—¶ (batch_size=4)
```
æ€»è€—æ—¶: 18.51ms
â”œâ”€â”€ Time embedding: 0.97ms (5.2%)
â”œâ”€â”€ Ego status processing: 3.07ms (16.6%)
â”œâ”€â”€ Encoder block: 19.26ms (104.0%)
â”‚   â”œâ”€â”€ VL projection & pooling: 4.50ms (23.4%)
â”‚   â”œâ”€â”€ Reasoning projection & pooling: 4.43ms (23.0%)
â”‚   â””â”€â”€ Transformer encoder: 11.06ms (57.4%)
â”œâ”€â”€ Input embedding & position: 0.87ms (4.7%)
â”œâ”€â”€ Decoder: 134.01ms (724%)  âš ï¸ ä¸»è¦ç“¶é¢ˆ
â”‚   â””â”€â”€ 12å±‚ï¼Œæ¯å±‚çº¦11.5ms
â””â”€â”€ Trajectory head: 4.08ms (22.0%)
```

### Diffusioné‡‡æ ·è¿‡ç¨‹ (10æ­¥)
```
æ€»è€—æ—¶: 197.97ms (0.198s)
â”œâ”€â”€ å¹³å‡æ¯æ­¥: 19.74ms
â”‚   â”œâ”€â”€ Model forward: 19.18ms (97.2%)  âš ï¸ ä¸»è¦å¼€é”€
â”‚   â””â”€â”€ Scheduler step: 0.39ms (2.0%)
```

## ğŸ”´ æ ¸å¿ƒé—®é¢˜è¯†åˆ«

### 1. **Decoderæ˜¯æœ€å¤§ç“¶é¢ˆ** (å å•æ¬¡forwardçš„72%)
- **12å±‚Decoder**: 134.01ms
- æ¯å±‚å¹³å‡: ~11.5ms
- Decoderæ¯”Encoderæ…¢äº†**6.96å€**

### 2. **ä¸ºä»€ä¹ˆ2ç§’è¿™ä¹ˆæ…¢ï¼Ÿ**
å®é™…æµ‹é‡æ˜¾ç¤º10æ­¥åªéœ€è¦200msï¼Œä½†ä½ æåˆ°éœ€è¦2ç§’ã€‚å¯èƒ½çš„åŸå› ï¼š
- âŒ å®é™…ä½¿ç”¨äº†æ›´å¤šæ¨ç†æ­¥æ•° (100æ­¥?)
- âŒ Batch size = 1 (æ²¡æœ‰å¹¶è¡Œä¼˜åŒ–)
- âŒ CPUæ¨ç†è€ŒéGPU
- âŒ é¢å¤–çš„æ•°æ®é¢„å¤„ç†/åå¤„ç†å¼€é”€
- âŒ VL/Reasoningç‰¹å¾æå–æœªåŒ…å«åœ¨è®¡æ—¶ä¸­

## ğŸ¯ ä¼˜åŒ–å»ºè®® (æŒ‰ä¼˜å…ˆçº§æ’åº)

### ä¼˜å…ˆçº§1: å‡å°‘æ¨ç†æ­¥æ•° â­â­â­â­â­
**å½“å‰**: å¯èƒ½ä½¿ç”¨100æ­¥
**å»ºè®®**: ä½¿ç”¨10æ­¥æˆ–æ›´å°‘

**ç†ç”±**: 
- 10æ­¥ä»…éœ€200ms
- DDPMå¯ä»¥ç”¨æ›´å°‘æ­¥æ•°è¾¾åˆ°ç›¸ä¼¼è´¨é‡
- ä½¿ç”¨DDIM schedulerå¯ä»¥ç”¨5æ­¥è¾¾åˆ°ç±»ä¼¼æ•ˆæœ

**å®æ–½**:
```python
# åœ¨configä¸­ä¿®æ”¹
num_inference_steps: 10  # ä»100å‡å°‘åˆ°10
# æˆ–è€ƒè™‘ä½¿ç”¨DDIM
from diffusers import DDIMScheduler
```

**é¢„æœŸæå‡**: å¯ä»2sé™åˆ°200ms (10å€)

---

### ä¼˜å…ˆçº§2: ä¼˜åŒ–Decoderæ¶æ„ â­â­â­â­
**é—®é¢˜**: Decoderå 72%çš„æ—¶é—´ï¼Œä½†å¯èƒ½è¿‡åº¦å¤æ‚

**ä¼˜åŒ–æ–¹æ¡ˆ**:

#### 2.1 å‡å°‘Decoderå±‚æ•°
```python
# å½“å‰: n_layer=12
# å»ºè®®: n_layer=6 æˆ– 8
TransformerForDiffusion(
    n_layer=6,  # ä»12å‡å°‘åˆ°6
    ...
)
```
**é¢„æœŸæå‡**: Decoderä»134msé™åˆ°67msï¼Œæ€»æ—¶é—´å‡å°‘36%

#### 2.2 ä½¿ç”¨Flash Attention
```python
# åœ¨CustomDecoderLayerä¸­å¯ç”¨
self.memory_vl_cross_attn = nn.MultiheadAttention(
    ...,
    batch_first=True,
    # å¯ç”¨Flash Attention (PyTorch 2.0+)
)
# éœ€è¦åœ¨forwardä¸­æ·»åŠ : is_causal=True, enable_gqa=True
```
**é¢„æœŸæå‡**: 20-30%çš„attentionåŠ é€Ÿ

#### 2.3 åˆå¹¶Cross Attention
å½“å‰æœ‰2ä¸ªcross attentionæ“ä½œï¼š
- Memory-VL Cross Attention
- Trajectory-Memory Cross Attention

è€ƒè™‘åˆå¹¶ä¸ºå•æ¬¡æ“ä½œæˆ–ä½¿ç”¨æ›´è½»é‡çš„èåˆæœºåˆ¶ã€‚

---

### ä¼˜å…ˆçº§3: ç¼“å­˜ä¸å¤ç”¨ â­â­â­â­
**é—®é¢˜**: Encoderåœ¨æ¯ä¸ªdiffusionæ­¥éƒ½é‡æ–°è®¡ç®—

**ä¼˜åŒ–æ–¹æ¡ˆ**:

#### 3.1 ç¼“å­˜Encoderè¾“å‡º
Encoderè¾“å‡ºï¼ˆmemory, vl_features, reasoning_featuresï¼‰åœ¨æ•´ä¸ªé‡‡æ ·è¿‡ç¨‹ä¸­æ˜¯**ä¸å˜çš„**ã€‚

```python
def conditional_sample(self, ...):
    # åªè®¡ç®—ä¸€æ¬¡
    with torch.no_grad():
        memory, vl_features, reasoning_features = self.encoder_block(
            vl_embeds, reasoning_embeds, cond
        )
    
    for t in scheduler.timesteps:
        # å¤ç”¨ç¼“å­˜çš„encoderè¾“å‡º
        model_output = model.decoder_only(
            trajectory, t, memory, vl_features, reasoning_features, ...
        )
```

**é¢„æœŸæå‡**: èŠ‚çœ19.26ms Ã— 10æ­¥ = 192.6ms (å‡ ä¹ç¿»å€)

---

### ä¼˜å…ˆçº§4: æ¨¡å‹é‡åŒ– â­â­â­
ä½¿ç”¨INT8æˆ–FP16é‡åŒ–

```python
# FP16æ¨ç†
model = model.half()
# æˆ–ä½¿ç”¨torch.compile (PyTorch 2.0+)
model = torch.compile(model)
```

**é¢„æœŸæå‡**: 30-50%åŠ é€Ÿ

---

### ä¼˜å…ˆçº§5: å‡å°æ¨¡å‹å°ºå¯¸ â­â­â­
```python
# å½“å‰é…ç½®
n_emb=768, n_head=12, n_layer=12

# å»ºè®®é…ç½®ï¼ˆè½»é‡ç‰ˆï¼‰
n_emb=512, n_head=8, n_layer=6

# æˆ–ä¸­ç­‰é…ç½®
n_emb=640, n_head=10, n_layer=8
```

**é¢„æœŸæå‡**: 50-70%åŠ é€Ÿï¼ˆéœ€é‡æ–°è®­ç»ƒï¼‰

---

### ä¼˜å…ˆçº§6: Batchä¼˜åŒ– â­â­
å¦‚æœå½“å‰batch_size=1ï¼Œå¢åŠ åˆ°4-8å¯ä»¥æå‡GPUåˆ©ç”¨ç‡ã€‚

---

## ğŸ“Š ç»¼åˆä¼˜åŒ–ç­–ç•¥

### æ–¹æ¡ˆA: å¿«é€Ÿä¼˜åŒ–ï¼ˆæ— éœ€é‡è®­ç»ƒï¼‰
1. âœ… å‡å°‘æ¨ç†æ­¥æ•°: 100â†’10 (**10å€åŠ é€Ÿ**)
2. âœ… ç¼“å­˜Encoderè¾“å‡º (**2å€åŠ é€Ÿ**)
3. âœ… ä½¿ç”¨FP16 (**1.3å€åŠ é€Ÿ**)

**æ€»é¢„æœŸ**: ä»2sé™åˆ° **~75ms** (26å€åŠ é€Ÿ)

### æ–¹æ¡ˆB: æ·±åº¦ä¼˜åŒ–ï¼ˆéœ€é‡è®­ç»ƒï¼‰
1. âœ… æ‰€æœ‰æ–¹æ¡ˆAçš„ä¼˜åŒ–
2. âœ… å‡å°‘Decoderå±‚: 12â†’6
3. âœ… å‡å°æ¨¡å‹: n_emb=768â†’512

**æ€»é¢„æœŸ**: ä»2sé™åˆ° **~30ms** (67å€åŠ é€Ÿ)

---

## ğŸ”§ ç«‹å³å¯æ‰§è¡Œçš„ä»£ç ä¿®æ”¹

### 1. ä¿®æ”¹configå‡å°‘æ¨ç†æ­¥æ•°
```yaml
# config/pdm_server.yaml
policy:
  num_inference_steps: 10  # ä»100æ”¹ä¸º10
```

### 2. æ·»åŠ Encoderç¼“å­˜
åœ¨ `diffusion_dit_carla_policy.py` ä¸­ä¿®æ”¹ `conditional_sample`:

```python
def conditional_sample(self, ...):
    # åœ¨å¾ªç¯å‰ç¼“å­˜encoderè¾“å‡º
    with torch.no_grad():
        # è·å–encoderçš„memoryç­‰
        timesteps_dummy = torch.zeros(cond.shape[0], device=cond.device)
        
        # åªè¿è¡Œencoderéƒ¨åˆ†ï¼ˆéœ€è¦ä¿®æ”¹modelæ”¯æŒï¼‰
        memory, vl_features, reasoning_features = self.model.encode_conditions(
            cond, gen_vit_tokens, reasoning_query_tokens
        )
    
    for t in scheduler.timesteps:
        # ä½¿ç”¨ç¼“å­˜çš„memory
        model_output = self.model.decode_trajectory(
            trajectory, t, memory, vl_features, reasoning_features, ego_status
        )
        ...
```

### 3. ä½¿ç”¨FP16
```python
# åœ¨æ¨¡å‹åŠ è½½å
self.model = self.model.half()
```

---

## âš¡ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **ç«‹å³**: ä¿®æ”¹configï¼Œå°†num_inference_stepsæ”¹ä¸º10
2. **ä»Šå¤©**: å®ç°Encoderç¼“å­˜
3. **æœ¬å‘¨**: æµ‹è¯•FP16æ¨ç†
4. **ä¸‹å‘¨**: å¦‚éœ€è¦ï¼Œå‡å°‘Decoderå±‚æ•°å¹¶é‡æ–°è®­ç»ƒ

é¢„æœŸå¯ä»¥å°†æ¨ç†æ—¶é—´ä»2sé™ä½åˆ°100msä»¥å†…ï¼
