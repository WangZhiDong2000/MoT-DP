#!/usr/bin/env python3
"""
BEV Feature Preprocessing Script

This script processes BEV images generated by generate_lidar_bev.py and extracts 
features using the pretrained bev_model_mot from InterfuserBEVEncoder.

The extracted features (lidar_token and lidar_token_global) are saved alongside 
the BEV images for efficient loading during training, avoiding repeated feature 
extraction.

Input:
    - BEV images: <scene_path>/lidar_bev/*.png (generated by generate_lidar_bev.py)
    
Output:
    - lidar_token: <scene_path>/lidar_bev_features/<frame_id>_token.npy
    - lidar_token_global: <scene_path>/lidar_bev_features/<frame_id>_token_global.npy

Usage:
    python preprocess_bev_features.py --input_dir /path/to/dataset --process_all
"""

import numpy as np
import torch
import torch.nn as nn
from PIL import Image
import os
import glob
import argparse
from pathlib import Path
import sys
from tqdm import tqdm

# Add project root to path
project_root = Path(__file__).resolve().parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from model.interfuser_bev_encoder import InterfuserBEVEncoder, load_lidar_submodules


def load_bev_encoder(pretrained_path, device='cuda'):
    """
    Load the BEV encoder model with pretrained weights
    
    Args:
        pretrained_path: Path to the pretrained checkpoint
        device: Device to load the model on
        
    Returns:
        model: Loaded BEV encoder model in eval mode
    """
    print(f"Loading BEV encoder from: {pretrained_path}")
    
    # Create encoder (only need bev_model_mot part)
    encoder = InterfuserBEVEncoder(
        perception_backbone=None,
        state_dim=9,
        feature_dim=256,
        use_group_norm=True,
        freeze_backbone=False,  # Set to False to load weights
        bev_input_size=(448, 448)
    )
    
    # Load pretrained weights
    if os.path.exists(pretrained_path):
        load_lidar_submodules(encoder, pretrained_path, strict=False, logger=None)
        print("✓ Pretrained weights loaded successfully")
    else:
        print(f"⚠ Warning: Pretrained weights not found at {pretrained_path}")
        print("  Continuing with random initialization...")
    
    # Move to device and set to eval mode
    encoder = encoder.to(device)
    encoder.eval()
    
    # Freeze all parameters
    for param in encoder.parameters():
        param.requires_grad = False
    
    return encoder


def preprocess_bev_image(image_path):
    """
    Load and preprocess a BEV image
    
    Args:
        image_path: Path to the BEV image
        
    Returns:
        image_tensor: Preprocessed image tensor (1, 3, 448, 448)
    """
    # Load image
    image = Image.open(image_path).convert('RGB')
    
    # Convert to numpy array and normalize to [0, 1]
    image_np = np.array(image).astype(np.float32) / 255.0
    
    # Convert to tensor (H, W, C) -> (C, H, W)
    image_tensor = torch.from_numpy(image_np).permute(2, 0, 1)
    
    # Add batch dimension
    image_tensor = image_tensor.unsqueeze(0)
    
    return image_tensor


def extract_bev_features(encoder, image_tensor, device='cuda'):
    """
    Extract BEV features using the encoder's bev_model_mot
    
    Args:
        encoder: BEV encoder model
        image_tensor: Preprocessed image tensor (1, 3, 448, 448)
        device: Device to run inference on
        
    Returns:
        lidar_token: Local spatial tokens (seq_len, 1, 512)
        lidar_token_global: Global context token (1, 1, 512)
    """
    image_tensor = image_tensor.to(device)
    
    with torch.no_grad():
        # Step 1: Use bev_model_mot to process the image
        # This returns lidar_token and lidar_token_global
        lidar_token, lidar_token_global = encoder.bev_model_mot(image_tensor)
        
        # Step 2: Add position encoding
        lidar_token = lidar_token + encoder.position_encoding(lidar_token)
        
        # Step 3: Reshape to sequence format
        lidar_token = lidar_token.flatten(2).permute(2, 0, 1)  # (seq_len, batch, embed_dim)
        lidar_token_global = lidar_token_global.permute(2, 0, 1)  # (1, batch, embed_dim)
        
        # Step 4: Concatenate local and global tokens
        lidar_tokens = torch.cat([lidar_token, lidar_token_global], dim=0)
        
        # Step 5: Pass through connector
        lidar_tokens = encoder.lidar_connector(lidar_tokens)
        
        # Separate back into local and global
        lidar_token = lidar_tokens[:-1]  # (seq_len, batch, 512)
        lidar_token_global = lidar_tokens[-1:]  # (1, batch, 512)
    
    return lidar_token, lidar_token_global


def process_scene(scene_path, encoder, device='cuda', force_reprocess=False):
    """
    Process all BEV images in a scene directory
    
    Args:
        scene_path: Path to the scene directory
        encoder: BEV encoder model
        device: Device to run inference on
        force_reprocess: If True, reprocess even if features already exist
        
    Returns:
        num_processed: Number of frames processed
    """
    # Define directories
    bev_image_dir = os.path.join(scene_path, 'lidar_bev')
    feature_dir = os.path.join(scene_path, 'lidar_bev_features')
    
    # Check if BEV images exist
    if not os.path.exists(bev_image_dir):
        print(f"  ⚠ No lidar_bev directory found in {scene_path}, skipping...")
        return 0
    
    # Get list of BEV images
    bev_images = sorted(glob.glob(os.path.join(bev_image_dir, '*.png')))
    if not bev_images:
        print(f"  ⚠ No BEV images found in {bev_image_dir}, skipping...")
        return 0
    
    # Create feature directory
    os.makedirs(feature_dir, exist_ok=True)
    
    # Process each frame
    num_processed = 0
    num_skipped = 0
    
    for image_path in tqdm(bev_images, desc="  Processing frames", leave=False):
        frame_id = os.path.splitext(os.path.basename(image_path))[0]
        
        # Define output paths (using .pt for PyTorch tensors)
        token_path = os.path.join(feature_dir, f'{frame_id}_token.pt')
        token_global_path = os.path.join(feature_dir, f'{frame_id}_token_global.pt')
        
        # Skip if features already exist (unless force_reprocess)
        if not force_reprocess and os.path.exists(token_path) and os.path.exists(token_global_path):
            num_skipped += 1
            continue
        
        try:
            # Preprocess image
            image_tensor = preprocess_bev_image(image_path)
            
            # Extract features
            lidar_token, lidar_token_global = extract_bev_features(encoder, image_tensor, device)
            
            # Save as PyTorch tensors (squeeze batch dimension and move to CPU)
            lidar_token_cpu = lidar_token.squeeze(1).cpu()  # (seq_len, 512)
            lidar_token_global_cpu = lidar_token_global.squeeze(1).cpu()  # (1, 512)
            
            torch.save(lidar_token_cpu, token_path)
            torch.save(lidar_token_global_cpu, token_global_path)
            
            num_processed += 1
            
        except Exception as e:
            print(f"\n    ✗ Error processing {frame_id}: {str(e)}")
            import traceback
            traceback.print_exc()
            continue
    
    if num_skipped > 0:
        print(f"  ✓ Processed {num_processed} frames, skipped {num_skipped} existing features")
    else:
        print(f"  ✓ Processed {num_processed} frames")
    
    return num_processed


def find_all_scenes(dataset_root):
    """
    Recursively find all scenes with lidar_bev directories
    
    Args:
        dataset_root: Root directory of the dataset
        
    Returns:
        scene_paths: List of scene directory paths
    """
    scene_paths = []
    
    # Method 1: Find all directories containing 'lidar_bev'
    for root, dirs, files in os.walk(dataset_root):
        if 'lidar_bev' in dirs:
            scene_paths.append(root)
    
    return sorted(scene_paths)


def process_all_scenes(dataset_root, pretrained_path, device='cuda', 
                       process_all=False, force_reprocess=False, 
                       scenario_filter=None):
    """
    Process all scenes in the dataset
    
    Args:
        dataset_root: Root directory of the dataset
        pretrained_path: Path to pretrained encoder weights
        device: Device to run inference on
        process_all: If False, only process the first scene
        force_reprocess: If True, reprocess even if features already exist
        scenario_filter: List of scenario names to filter (e.g., ['Accident', 'ControlLoss'])
    """
    # Load encoder
    encoder = load_bev_encoder(pretrained_path, device)
    
    # Find all scenes
    all_scenes = find_all_scenes(dataset_root)
    
    if not all_scenes:
        print(f"✗ No scenes with lidar_bev directories found in {dataset_root}")
        return
    
    # Apply scenario filter if provided
    if scenario_filter:
        filtered_scenes = []
        for scene_path in all_scenes:
            for scenario in scenario_filter:
                if scenario in scene_path:
                    filtered_scenes.append(scene_path)
                    break
        all_scenes = filtered_scenes
        print(f"Filtered to {len(all_scenes)} scenes matching scenarios: {scenario_filter}")
    
    # Limit to first scene if not processing all
    if not process_all:
        all_scenes = all_scenes[:1]
        print("Processing only the first scene (use --process_all to process all)")
    
    print(f"\nFound {len(all_scenes)} scenes to process")
    print("=" * 70)
    
    # Process each scene
    total_frames = 0
    for i, scene_path in enumerate(all_scenes, 1):
        relative_path = os.path.relpath(scene_path, dataset_root)
        print(f"\n[{i}/{len(all_scenes)}] Processing: {relative_path}")
        
        num_processed = process_scene(scene_path, encoder, device, force_reprocess)
        total_frames += num_processed
    
    print("\n" + "=" * 70)
    print(f"✓ Processing complete!")
    print(f"  Total scenes processed: {len(all_scenes)}")
    print(f"  Total frames processed: {total_frames}")
    print("=" * 70)


def verify_features(feature_dir, frame_id):
    """
    Verify that saved features can be loaded correctly
    
    Args:
        feature_dir: Directory containing the features
        frame_id: Frame ID to verify
    """
    token_path = os.path.join(feature_dir, f'{frame_id}_token.pt')
    token_global_path = os.path.join(feature_dir, f'{frame_id}_token_global.pt')
    
    if not os.path.exists(token_path) or not os.path.exists(token_global_path):
        print(f"✗ Features not found for frame {frame_id}")
        return False
    
    try:
        lidar_token = torch.load(token_path)
        lidar_token_global = torch.load(token_global_path)
        
        print(f"✓ Features loaded successfully:")
        print(f"  lidar_token shape: {lidar_token.shape}")
        print(f"  lidar_token_global shape: {lidar_token_global.shape}")
        print(f"  lidar_token stats: mean={lidar_token.mean():.4f}, std={lidar_token.std():.4f}")
        print(f"  lidar_token_global stats: mean={lidar_token_global.mean():.4f}, std={lidar_token_global.std():.4f}")
        
        return True
    except Exception as e:
        print(f"✗ Error loading features: {e}")
        return False


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Preprocess BEV features for efficient training')
    parser.add_argument('--input_dir', type=str,
                       default='/home/wang/Project/carla_garage/data',
                       help='Root directory of the dataset containing lidar_bev folders')
    parser.add_argument('--pretrained_path', type=str,
                       default='/home/wang/Project/MoT-DP/model/interfuser/lidar_bev_encoder_only.pth',
                       help='Path to pretrained encoder weights')
    parser.add_argument('--device', type=str, default='cuda',
                       choices=['cuda', 'cpu'],
                       help='Device to run inference on')
    parser.add_argument('--process_all', action='store_true', default=True,
                       help='Process all scenes (default: only first scene for testing)')
    parser.add_argument('--force_reprocess', action='store_true', default=False,
                       help='Force reprocessing even if features already exist')
    parser.add_argument('--scenarios', type=str, nargs='+',
                       help='Filter by scenario names (e.g., Accident ControlLoss)')
    parser.add_argument('--verify', type=str,
                       help='Verify features for a specific scene and frame (format: scene_path:frame_id)')
    
    args = parser.parse_args()
    
    # Verify mode
    if args.verify:
        parts = args.verify.split(':')
        if len(parts) != 2:
            print("Error: --verify format should be 'scene_path:frame_id'")
            sys.exit(1)
        
        scene_path, frame_id = parts
        feature_dir = os.path.join(scene_path, 'lidar_bev_features')
        verify_features(feature_dir, frame_id)
        sys.exit(0)
    
    # Check if input directory exists
    if not os.path.exists(args.input_dir):
        print(f"✗ Error: Input directory '{args.input_dir}' does not exist!")
        sys.exit(1)
    
    # Check if pretrained weights exist
    if not os.path.exists(args.pretrained_path):
        print(f"⚠ Warning: Pretrained weights not found at '{args.pretrained_path}'")
        response = input("Continue with random initialization? (y/n): ")
        if response.lower() != 'y':
            sys.exit(1)
    
    # Check CUDA availability
    if args.device == 'cuda' and not torch.cuda.is_available():
        print("⚠ Warning: CUDA not available, falling back to CPU")
        args.device = 'cpu'
    
    print("\n" + "=" * 70)
    print("BEV Feature Preprocessing")
    print("=" * 70)
    print(f"Input directory: {args.input_dir}")
    print(f"Pretrained weights: {args.pretrained_path}")
    print(f"Device: {args.device}")
    print(f"Process all: {args.process_all}")
    print(f"Force reprocess: {args.force_reprocess}")
    if args.scenarios:
        print(f"Scenario filter: {args.scenarios}")
    print("=" * 70)
    
    # Process all scenes
    process_all_scenes(
        dataset_root=args.input_dir,
        pretrained_path=args.pretrained_path,
        device=args.device,
        process_all=args.process_all,
        force_reprocess=args.force_reprocess,
        scenario_filter=args.scenarios
    )
