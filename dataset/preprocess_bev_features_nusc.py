#!/usr/bin/env python3
"""
BEV Feature Preprocessing Script for nuScenes Dataset

This script processes BEV images generated by generate_lidar_bev_nusc.py and extracts 
features using the pretrained bev_model_mot from InterfuserBEVEncoder.

The extracted features (lidar_token and lidar_token_global) are saved for efficient 
loading during training, avoiding repeated feature extraction.

Input:
    - BEV images: <dataset_root>/samples/LIDAR_TOP_BEV/*.png
    
Output:
    - lidar_token: <dataset_root>/samples/LIDAR_TOP_BEV_FEATURES/<frame_id>_token.pt
    - lidar_token_global: <dataset_root>/samples/LIDAR_TOP_BEV_FEATURES/<frame_id>_token_global.pt

Usage:
    python preprocess_bev_features_nusc.py --input_dir /path/to/v1.0-mini
"""

import numpy as np
import torch
import torch.nn as nn
from PIL import Image
import os
import glob
import argparse
from pathlib import Path
import sys
from tqdm import tqdm

# Add project root to path
project_root = Path(__file__).resolve().parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from model.interfuser_bev_encoder import InterfuserBEVEncoder, load_lidar_submodules


def load_bev_encoder(pretrained_path, device='cuda'):
    """
    Load the BEV encoder model with pretrained weights
    
    Args:
        pretrained_path: Path to the pretrained checkpoint
        device: Device to load the model on
        
    Returns:
        model: Loaded BEV encoder model in eval mode
    """
    print(f"Loading BEV encoder from: {pretrained_path}")
    
    # Create encoder (only need bev_model_mot part)
    encoder = InterfuserBEVEncoder(
        perception_backbone=None,
        state_dim=9,
        feature_dim=256,
        use_group_norm=True,
        freeze_backbone=False,  # Set to False to load weights
        bev_input_size=(448, 448)
    )
    
    # Load pretrained weights
    if os.path.exists(pretrained_path):
        load_lidar_submodules(encoder, pretrained_path, strict=False, logger=None)
        print("✓ Pretrained weights loaded successfully")
    else:
        print(f"⚠ Warning: Pretrained weights not found at {pretrained_path}")
        print("  Continuing with random initialization...")
    
    # Move to device and set to eval mode
    encoder = encoder.to(device)
    encoder.eval()
    
    # Freeze all parameters
    for param in encoder.parameters():
        param.requires_grad = False
    
    return encoder


def preprocess_bev_image(image_path):
    """
    Load and preprocess a BEV image
    
    Args:
        image_path: Path to the BEV image
        
    Returns:
        image_tensor: Preprocessed image tensor (1, 3, 448, 448)
    """
    # Load image
    image = Image.open(image_path).convert('RGB')
    
    # Convert to numpy array and normalize to [0, 1]
    image_np = np.array(image, dtype=np.float32) / 255.0
    
    # Convert to tensor directly (H, W, C) -> (C, H, W)
    # Use torch.tensor instead of torch.from_numpy to avoid type checking issues
    image_tensor = torch.tensor(image_np, dtype=torch.float32).permute(2, 0, 1)
    
    # Add batch dimension
    image_tensor = image_tensor.unsqueeze(0)
    
    return image_tensor


def extract_bev_features(encoder, image_tensor, device='cuda'):
    """
    Extract BEV features using the encoder's bev_model_mot
    
    Args:
        encoder: BEV encoder model
        image_tensor: Preprocessed image tensor (1, 3, 448, 448)
        device: Device to run inference on
        
    Returns:
        lidar_token: Local spatial tokens (seq_len, 1, 512)
        lidar_token_global: Global context token (1, 1, 512)
    """
    image_tensor = image_tensor.to(device)
    
    with torch.no_grad():
        # Step 1: Use bev_model_mot to process the image
        # This returns lidar_token and lidar_token_global
        lidar_token, lidar_token_global = encoder.bev_model_mot(image_tensor)
        
        # Step 2: Add position encoding
        lidar_token = lidar_token + encoder.position_encoding(lidar_token)
        
        # Step 3: Reshape to sequence format
        lidar_token = lidar_token.flatten(2).permute(2, 0, 1)  # (seq_len, batch, embed_dim)
        lidar_token_global = lidar_token_global.permute(2, 0, 1)  # (1, batch, embed_dim)
        
        # Step 4: Concatenate local and global tokens
        lidar_tokens = torch.cat([lidar_token, lidar_token_global], dim=0)
        
        # Step 5: Pass through connector
        lidar_tokens = encoder.lidar_connector(lidar_tokens)
        
        # Separate back into local and global
        lidar_token = lidar_tokens[:-1]  # (seq_len, batch, 512)
        lidar_token_global = lidar_tokens[-1:]  # (1, batch, 512)
    
    return lidar_token, lidar_token_global


def process_nuscenes_bev(dataset_root, encoder, device='cuda', force_reprocess=False):
    """
    Process nuScenes BEV images
    
    Args:
        dataset_root: Root directory of the nuScenes dataset
        encoder: BEV encoder model
        device: Device to run inference on
        force_reprocess: If True, reprocess even if features already exist
        
    Returns:
        num_processed: Number of frames processed
    """
    # Define directories for nuScenes
    bev_image_dir = os.path.join(dataset_root, 'samples', 'LIDAR_TOP_BEV')
    feature_dir = os.path.join(dataset_root, 'samples', 'LIDAR_TOP_BEV_FEATURES')
    
    # Check if BEV images exist
    if not os.path.exists(bev_image_dir):
        print(f"  ✗ No LIDAR_TOP_BEV directory found at {bev_image_dir}")
        return 0
    
    # Get list of BEV images
    bev_images = sorted(glob.glob(os.path.join(bev_image_dir, '*.png')))
    if not bev_images:
        print(f"  ✗ No BEV images found in {bev_image_dir}")
        return 0
    
    # Create feature directory
    os.makedirs(feature_dir, exist_ok=True)
    
    print(f"  Found {len(bev_images)} BEV images to process")
    print(f"  Output directory: {feature_dir}")
    
    # Process each frame
    num_processed = 0
    num_skipped = 0
    
    for image_path in tqdm(bev_images, desc="  Processing frames"):
        frame_id = os.path.splitext(os.path.basename(image_path))[0]
        
        # Define output paths (using .pt for PyTorch tensors)
        token_path = os.path.join(feature_dir, f'{frame_id}_token.pt')
        token_global_path = os.path.join(feature_dir, f'{frame_id}_token_global.pt')
        
        # Skip if features already exist (unless force_reprocess)
        if not force_reprocess and os.path.exists(token_path) and os.path.exists(token_global_path):
            num_skipped += 1
            continue
        
        try:
            # Preprocess image
            image_tensor = preprocess_bev_image(image_path)
            
            # Extract features
            lidar_token, lidar_token_global = extract_bev_features(encoder, image_tensor, device)
            
            # Save as PyTorch tensors (squeeze batch dimension and move to CPU)
            lidar_token_cpu = lidar_token.squeeze(1).cpu()  # (seq_len, 512)
            lidar_token_global_cpu = lidar_token_global.squeeze(1).cpu()  # (1, 512)
            
            torch.save(lidar_token_cpu, token_path)
            torch.save(lidar_token_global_cpu, token_global_path)
            
            num_processed += 1
            
        except Exception as e:
            print(f"\n    ✗ Error processing {frame_id}: {str(e)}")
            import traceback
            traceback.print_exc()
            continue
    
    if num_skipped > 0:
        print(f"  ✓ Processed {num_processed} frames, skipped {num_skipped} existing features")
    else:
        print(f"  ✓ Processed {num_processed} frames")
    
    return num_processed



def process_nuscenes_dataset(dataset_root, pretrained_path, device='cuda', 
                            force_reprocess=False):
    """
    Process nuScenes dataset BEV features
    
    Args:
        dataset_root: Root directory of the nuScenes dataset
        pretrained_path: Path to pretrained encoder weights
        device: Device to run inference on
        force_reprocess: If True, reprocess even if features already exist
    """
    # Load encoder
    encoder = load_bev_encoder(pretrained_path, device)
    
    print(f"\nProcessing nuScenes dataset at: {dataset_root}")
    print("=" * 70)
    
    # Process BEV images
    num_processed = process_nuscenes_bev(dataset_root, encoder, device, force_reprocess)
    
    print("\n" + "=" * 70)
    print(f"✓ Processing complete!")
    print(f"  Total frames processed: {num_processed}")
    print("=" * 70)




def verify_features(feature_dir, frame_id):
    """
    Verify that saved features can be loaded correctly
    
    Args:
        feature_dir: Directory containing the features
        frame_id: Frame ID to verify
    """
    token_path = os.path.join(feature_dir, f'{frame_id}_token.pt')
    token_global_path = os.path.join(feature_dir, f'{frame_id}_token_global.pt')
    
    if not os.path.exists(token_path) or not os.path.exists(token_global_path):
        print(f"✗ Features not found for frame {frame_id}")
        return False
    
    try:
        lidar_token = torch.load(token_path)
        lidar_token_global = torch.load(token_global_path)
        
        print(f"✓ Features loaded successfully:")
        print(f"  lidar_token shape: {lidar_token.shape}")
        print(f"  lidar_token_global shape: {lidar_token_global.shape}")
        print(f"  lidar_token stats: mean={lidar_token.mean():.4f}, std={lidar_token.std():.4f}")
        print(f"  lidar_token_global stats: mean={lidar_token_global.mean():.4f}, std={lidar_token_global.std():.4f}")
        
        return True
    except Exception as e:
        print(f"✗ Error loading features: {e}")
        return False


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Preprocess BEV features for nuScenes dataset')
    parser.add_argument('--input_dir', type=str,
                       default='/home/wang/Dataset/v1.0-mini',
                       help='Root directory of the nuScenes dataset')
    parser.add_argument('--pretrained_path', type=str,
                       default='/home/wang/Project/MoT-DP/model/interfuser/lidar_bev_encoder_only.pth',
                       help='Path to pretrained encoder weights')
    parser.add_argument('--device', type=str, default='cuda',
                       choices=['cuda', 'cpu'],
                       help='Device to run inference on')
    parser.add_argument('--force_reprocess', action='store_true', default=False,
                       help='Force reprocessing even if features already exist')
    parser.add_argument('--verify', type=str,
                       help='Verify features for a specific frame (format: frame_id)')
    
    args = parser.parse_args()
    
    # Verify mode
    if args.verify:
        feature_dir = os.path.join(args.input_dir, 'samples', 'LIDAR_TOP_BEV_FEATURES')
        verify_features(feature_dir, args.verify)
        sys.exit(0)
    
    # Check if input directory exists
    if not os.path.exists(args.input_dir):
        print(f"✗ Error: Input directory '{args.input_dir}' does not exist!")
        sys.exit(1)
    
    # Check if pretrained weights exist
    if not os.path.exists(args.pretrained_path):
        print(f"⚠ Warning: Pretrained weights not found at '{args.pretrained_path}'")
        response = input("Continue with random initialization? (y/n): ")
        if response.lower() != 'y':
            sys.exit(1)
    
    # Check CUDA availability
    if args.device == 'cuda' and not torch.cuda.is_available():
        print("⚠ Warning: CUDA not available, falling back to CPU")
        args.device = 'cpu'
    
    print("\n" + "=" * 70)
    print("nuScenes BEV Feature Preprocessing")
    print("=" * 70)
    print(f"Input directory: {args.input_dir}")
    print(f"Pretrained weights: {args.pretrained_path}")
    print(f"Device: {args.device}")
    print(f"Force reprocess: {args.force_reprocess}")
    print("=" * 70)
    
    # Process nuScenes dataset
    process_nuscenes_dataset(
        dataset_root=args.input_dir,
        pretrained_path=args.pretrained_path,
        device=args.device,
        force_reprocess=args.force_reprocess
    )
