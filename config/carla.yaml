
dataloader:
  batch_size: 32       
  num_workers: 8       
  persistent_workers: true
  pin_memory: true
  shuffle: true

# Horizon settings 
obs_horizon: 2         
pred_horizon: 6        
action_horizon: 4      
n_obs_steps: 2

# EMA settings
ema:
  inv_gamma: 1.0
  max_value: 0.9999
  min_value: 0.0
  power: 0.75
  update_after_step: 0

# Optimizer settings
optimizer:
  _target_: torch.optim.AdamW
  betas:
  - 0.9        # 训练稳定性
  - 0.999
  eps: 1.0e-08
  lr: 5.0e-05  
  weight_decay: 1.0e-05  # weight decay防止过拟合

# Shape meta - CARLA数据集
shape_meta:
  action:
    shape:
    - 2           # throttle, steer
  obs:
    agent_pos:
      shape:
      - 2
      type: low_dim
    image:
      shape:
      - 3
      - 96
      - 96
      type: rgb
    speed:
      shape:
      - 1
      type: low_dim
    theta:
      shape:
      - 1  
      type: low_dim
    target_point:
      shape:
      - 2
      type: low_dim

# Action normalization settings
enable_action_normalization: true  # 启用action normalization

# Policy configuration for DiT 
policy:
  input_dim: 2        # action_dim 
  output_dim: 2       # action_dim  
  horizon: 4          # 与action_horizon保持一致
  n_obs_steps: 2      # obs_horizon
  cond_dim: 256       # TCP模型j_ctrl特征维度
  obs_as_global_cond: true
  
  # Transformer architecture 
  n_layer: 8          
  n_head: 8           
  n_emb: 512          
  p_drop_emb: 0.1    
  p_drop_attn: 0.1   
  
  # Attention settings
  causal_attn: true
  time_as_cond: true
  obs_as_cond: true
  n_cond_layers: 4    
  action_horizon: 4
  num_inference_steps: 100  

# Noise scheduler configuration 
noise_scheduler:
  num_diffusion_steps: 100    
  beta_start: 0.0001
  beta_end: 0.02
  beta_schedule: "squaredcos_cap_v2"  
  clip_sample: false
  prediction_type: "epsilon" # 预测目标为噪声/目标动作

# Training settings 
training:
  num_epochs: 300            
  max_grad_norm: 1.0        
  dataset_path: "/home/wang/projects/diffusion_policy_z/data/tmp_data"  
  lr_final: 1e-7           
  validation_freq: 5      # 每10个epoch进行一次验证
  save_freq: 5            # 每5个epoch保存一次模型
  early_stopping_patience: 10  # 早停机制

# Logging - wandb配置
logging:
  use_wandb: true
  wandb_project: "carla-diffusion-policy"
  run_name: "carla_dit_optimized"
  checkpoint_dir: "/home/wang/projects/diffusion_policy_z/checkpoints/carla_dit"
  save_every: 5
  log_freq: 10             

# Evaluation settings 
eval:
  num_episodes: 10         
  max_steps: 500          
  success_threshold: 0.1   
  eval_freq: 10            

# Data augmentation 
data_augmentation:
  enable: true
  image_noise_std: 0.02   
  action_noise_std: 0.01 
  random_crop: false      

# Model optimization 
model_optimization:
  use_mixed_precision: true    # 使用混合精度训练
  gradient_accumulation_steps: 2  # 梯度累积步数
  warmup_steps: 500           # 学习率预热步数
  lr_scheduler: "cosine"      # 余弦学习率调度