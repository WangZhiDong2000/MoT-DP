#!/usr/bin/env python3
"""
ç»´åº¦å…¼å®¹æ€§æ£€æŸ¥å’Œé…ç½®å¯¹æ¯”å·¥å…·
ç”¨äºéªŒè¯æ¨¡å‹ç»´åº¦é…ç½®æ˜¯å¦åˆç†
"""

import yaml
import sys
import argparse
from pathlib import Path
from typing import Dict, Tuple

def load_config(config_path: str) -> Dict:
    """åŠ è½½YAMLé…ç½®æ–‡ä»¶"""
    with open(config_path, 'r') as f:
        return yaml.safe_load(f)

def save_config(config: Dict, config_path: str):
    """ä¿å­˜YAMLé…ç½®æ–‡ä»¶"""
    with open(config_path, 'w') as f:
        yaml.dump(config, f, default_flow_style=False, sort_keys=False)

def check_dimension_compatibility(config: Dict) -> Tuple[bool, list]:
    """
    æ£€æŸ¥ç»´åº¦é…ç½®çš„å…¼å®¹æ€§
    è¿”å›: (æ˜¯å¦å…¼å®¹, é”™è¯¯/è­¦å‘Šåˆ—è¡¨)
    """
    issues = []
    policy = config.get('policy', {})
    bev_encoder = config.get('bev_encoder', {})
    
    n_emb = policy.get('n_emb', 512)
    n_head = policy.get('n_head', 8)
    n_layer = policy.get('n_layer', 8)
    n_cond_layers = policy.get('n_cond_layers', 4)
    feature_dim = bev_encoder.get('feature_dim', 256)
    state_dim = bev_encoder.get('state_dim', 15)
    
    # æ£€æŸ¥1: n_embå¿…é¡»èƒ½è¢«n_headæ•´é™¤
    if n_emb % n_head != 0:
        issues.append({
            'level': 'ERROR',
            'message': f'n_emb ({n_emb}) å¿…é¡»èƒ½è¢« n_head ({n_head}) æ•´é™¤',
            'suggestion': f'å»ºè®®æ”¹ä¸º: n_emb={n_head * (n_emb // n_head)} æˆ– n_head={n_emb // (n_emb // n_head)}'
        })
    
    # æ£€æŸ¥2: æ¯ä¸ªæ³¨æ„åŠ›å¤´çš„ç»´åº¦åº”è¯¥åœ¨64-256ä¹‹é—´
    head_dim = n_emb // n_head if n_head > 0 else 0
    if head_dim < 32:
        issues.append({
            'level': 'WARNING',
            'message': f'æ¯ä¸ªæ³¨æ„åŠ›å¤´ç»´åº¦ ({head_dim}) è¿‡å°ï¼Œå¯èƒ½å½±å“æ€§èƒ½',
            'suggestion': f'å»ºè®®å¢åŠ  n_emb æˆ–å‡å°‘ n_head'
        })
    elif head_dim > 256:
        issues.append({
            'level': 'WARNING',
            'message': f'æ¯ä¸ªæ³¨æ„åŠ›å¤´ç»´åº¦ ({head_dim}) è¿‡å¤§ï¼Œå¯èƒ½æµªè´¹è®¡ç®—',
            'suggestion': f'å»ºè®®å‡å°‘ n_emb æˆ–å¢åŠ  n_head'
        })
    
    # æ£€æŸ¥3: n_embåº”è¯¥æ˜¯4çš„å€æ•°
    if n_emb % 4 != 0:
        issues.append({
            'level': 'ERROR',
            'message': f'n_emb ({n_emb}) åº”è¯¥æ˜¯4çš„å€æ•°',
            'suggestion': f'å»ºè®®æ”¹ä¸º: n_emb={(n_emb // 4) * 4}'
        })
    
    # æ£€æŸ¥4: feature_dimä¸n_embçš„å…³ç³»
    ratio = feature_dim / n_emb if n_emb > 0 else 0
    if ratio < 0.25:
        issues.append({
            'level': 'WARNING',
            'message': f'feature_dim ({feature_dim}) ç›¸å¯¹äº n_emb ({n_emb}) å¤ªå° (æ¯”ä¾‹ {ratio:.2f})',
            'suggestion': f'å»ºè®®å¢åŠ  feature_dim æˆ–å‡å°‘ n_emb'
        })
    elif ratio > 2:
        issues.append({
            'level': 'WARNING',
            'message': f'feature_dim ({feature_dim}) ç›¸å¯¹äº n_emb ({n_emb}) å¤ªå¤§ (æ¯”ä¾‹ {ratio:.2f})',
            'suggestion': f'å»ºè®®å‡å°‘ feature_dim æˆ–å¢åŠ  n_emb'
        })
    
    # æ£€æŸ¥5: å±‚æ•°çš„åˆç†èŒƒå›´
    if n_layer < 2:
        issues.append({
            'level': 'WARNING',
            'message': f'n_layer ({n_layer}) è¿‡å°ï¼Œå¯èƒ½å½±å“æ¨¡å‹å®¹é‡',
            'suggestion': f'å»ºè®®è‡³å°‘è®¾ç½®ä¸º 4'
        })
    elif n_layer > 32:
        issues.append({
            'level': 'WARNING',
            'message': f'n_layer ({n_layer}) è¿‡å¤§ï¼Œå¯èƒ½å¯¼è‡´è®­ç»ƒå›°éš¾',
            'suggestion': f'å»ºè®®ä¸è¶…è¿‡ 16'
        })
    
    if n_cond_layers < 2:
        issues.append({
            'level': 'WARNING',
            'message': f'n_cond_layers ({n_cond_layers}) è¿‡å°',
            'suggestion': f'å»ºè®®è‡³å°‘è®¾ç½®ä¸º 2'
        })
    elif n_cond_layers > 16:
        issues.append({
            'level': 'WARNING',
            'message': f'n_cond_layers ({n_cond_layers}) è¿‡å¤§',
            'suggestion': f'å»ºè®®ä¸è¶…è¿‡ 8'
        })
    
    return len([i for i in issues if i['level'] == 'ERROR']) == 0, issues

def estimate_memory_and_speed(config: Dict) -> Dict:
    """
    ä¼°è®¡æ˜¾å­˜ä½¿ç”¨å’Œç›¸å¯¹è®­ç»ƒé€Ÿåº¦
    """
    policy = config.get('policy', {})
    bev_encoder = config.get('bev_encoder', {})
    dataloader = config.get('dataloader', {})
    
    n_emb = policy.get('n_emb', 512)
    n_head = policy.get('n_head', 8)
    n_layer = policy.get('n_layer', 8)
    n_cond_layers = policy.get('n_cond_layers', 4)
    feature_dim = bev_encoder.get('feature_dim', 256)
    batch_size = dataloader.get('batch_size', 128)
    
    # åŸºå‡†é…ç½®ï¼ˆ512, 8, 8, 4ï¼‰å¯¹åº”100%
    baseline_n_emb = 512
    baseline_n_head = 8
    baseline_n_layer = 8
    baseline_n_cond_layers = 4
    
    # è®¡ç®—å†…å­˜å› å­
    emb_factor = (n_emb / baseline_n_emb) ** 2
    layer_factor = (n_layer / baseline_n_layer) * 0.5
    cond_factor = (n_cond_layers / baseline_n_cond_layers) * 0.3
    feature_factor = (feature_dim / 256) * 0.2
    
    memory_factor = emb_factor + layer_factor + cond_factor + feature_factor
    
    # è®¡ç®—é€Ÿåº¦å› å­
    speed_factor = (n_emb / baseline_n_emb) * (n_layer / baseline_n_layer) * \
                   (n_cond_layers / baseline_n_cond_layers) * 0.5 + 0.5
    
    return {
        'memory_factor': memory_factor,
        'memory_percentage': f"{memory_factor * 100:.0f}%",
        'speed_factor': speed_factor,
        'speed_relative': f"{speed_factor:.1f}x (ä¸åŸºå‡†é…ç½®ç›¸æ¯”)",
        'estimated_gpu_memory_gb': f"~{memory_factor * 16:.1f} GB (å‡è®¾åŸºå‡†é…ç½®16GB)",
        'batch_size': batch_size,
        'total_params_millions': estimate_params(n_emb, n_layer, n_cond_layers, feature_dim)
    }

def estimate_params(n_emb: int, n_layer: int, n_cond_layers: int, feature_dim: int) -> float:
    """ä¼°è®¡æ¨¡å‹å‚æ•°é‡ï¼ˆç™¾ä¸‡ï¼‰"""
    # ç®€å•ä¼°è®¡
    transformer_params = (n_emb * n_emb * 4 * n_layer) / 1e6
    cond_encoder_params = (feature_dim * n_emb + n_emb * n_emb * 4 * n_cond_layers) / 1e6
    return transformer_params + cond_encoder_params

def print_compatibility_report(config_path: str):
    """æ‰“å°å®Œæ•´çš„å…¼å®¹æ€§æŠ¥å‘Š"""
    config = load_config(config_path)
    is_compatible, issues = check_dimension_compatibility(config)
    resources = estimate_memory_and_speed(config)
    
    print("\n" + "="*80)
    print("ğŸ“Š ç»´åº¦å…¼å®¹æ€§æ£€æŸ¥æŠ¥å‘Š".center(80))
    print("="*80)
    
    # é…ç½®ä¿¡æ¯
    print("\nğŸ“ å½“å‰é…ç½®:")
    policy = config.get('policy', {})
    bev_encoder = config.get('bev_encoder', {})
    print(f"  â€¢ n_emb: {policy.get('n_emb', 512)}")
    print(f"  â€¢ n_head: {policy.get('n_head', 8)}")
    print(f"  â€¢ n_layer: {policy.get('n_layer', 8)}")
    print(f"  â€¢ n_cond_layers: {policy.get('n_cond_layers', 4)}")
    print(f"  â€¢ feature_dim: {bev_encoder.get('feature_dim', 256)}")
    
    # è®¡ç®—å€¼
    n_emb = policy.get('n_emb', 512)
    n_head = policy.get('n_head', 8)
    head_dim = n_emb // n_head if n_head > 0 else 0
    print(f"\nğŸ”¢ è®¡ç®—å€¼:")
    print(f"  â€¢ æ¯ä¸ªæ³¨æ„åŠ›å¤´ç»´åº¦: {head_dim}")
    print(f"  â€¢ feature_dim / n_emb æ¯”ä¾‹: {bev_encoder.get('feature_dim', 256) / n_emb:.2f}")
    
    # å…¼å®¹æ€§æ£€æŸ¥
    status = "âœ… é€šè¿‡" if is_compatible else "âŒ å¤±è´¥"
    print(f"\n{status} å…¼å®¹æ€§æ£€æŸ¥:")
    if issues:
        for issue in issues:
            icon = "ğŸ”´" if issue['level'] == 'ERROR' else "ğŸŸ¡"
            print(f"\n  {icon} [{issue['level']}] {issue['message']}")
            print(f"     ğŸ’¡ {issue['suggestion']}")
    else:
        print("  âœ… æ‰€æœ‰æ£€æŸ¥éƒ½é€šè¿‡!")
    
    # èµ„æºä¼°è®¡
    print(f"\nğŸ“ˆ èµ„æºä¼°è®¡:")
    print(f"  â€¢ ç›¸å¯¹æ˜¾å­˜å ç”¨: {resources['memory_percentage']}")
    print(f"  â€¢ ä¼°è®¡GPUæ˜¾å­˜: {resources['estimated_gpu_memory_gb']}")
    print(f"  â€¢ ç›¸å¯¹è®­ç»ƒé€Ÿåº¦: {resources['speed_relative']}")
    print(f"  â€¢ ä¼°è®¡å‚æ•°é‡: {resources['total_params_millions']:.1f}M")
    
    print("\n" + "="*80)

def compare_configs(config1_path: str, config2_path: str):
    """å¯¹æ¯”ä¸¤ä¸ªé…ç½®"""
    config1 = load_config(config1_path)
    config2 = load_config(config2_path)
    
    print("\n" + "="*80)
    print("ğŸ“Š é…ç½®å¯¹æ¯”æŠ¥å‘Š".center(80))
    print("="*80)
    
    print(f"\né…ç½®1: {config1_path}")
    print_config_summary(config1)
    
    print(f"\né…ç½®2: {config2_path}")
    print_config_summary(config2)
    
    # å·®å¼‚åˆ†æ
    print("\nğŸ“Š å·®å¼‚åˆ†æ:")
    policy1 = config1.get('policy', {})
    policy2 = config2.get('policy', {})
    bev1 = config1.get('bev_encoder', {})
    bev2 = config2.get('bev_encoder', {})
    
    diff_items = [
        ('n_emb', policy1.get('n_emb'), policy2.get('n_emb')),
        ('n_head', policy1.get('n_head'), policy2.get('n_head')),
        ('n_layer', policy1.get('n_layer'), policy2.get('n_layer')),
        ('n_cond_layers', policy1.get('n_cond_layers'), policy2.get('n_cond_layers')),
        ('feature_dim', bev1.get('feature_dim'), bev2.get('feature_dim')),
    ]
    
    for name, val1, val2 in diff_items:
        if val1 != val2:
            change = ((val2 - val1) / val1 * 100) if val1 != 0 else 0
            symbol = "â¬†ï¸ " if change > 0 else "â¬‡ï¸ "
            print(f"  {symbol} {name}: {val1} â†’ {val2} ({change:+.0f}%)")
    
    # èµ„æºå¯¹æ¯”
    res1 = estimate_memory_and_speed(config1)
    res2 = estimate_memory_and_speed(config2)
    
    print(f"\nğŸ“ˆ èµ„æºå¯¹æ¯”:")
    print(f"  å†…å­˜å ç”¨: {res1['memory_percentage']} â†’ {res2['memory_percentage']}")
    print(f"  è®­ç»ƒé€Ÿåº¦: {res1['speed_relative']} â†’ {res2['speed_relative']}")
    
    print("\n" + "="*80)

def print_config_summary(config: Dict):
    """æ‰“å°é…ç½®æ‘˜è¦"""
    policy = config.get('policy', {})
    bev_encoder = config.get('bev_encoder', {})
    resources = estimate_memory_and_speed(config)
    
    print(f"  â€¢ n_emb: {policy.get('n_emb', 512)}")
    print(f"  â€¢ n_head: {policy.get('n_head', 8)}")
    print(f"  â€¢ n_layer: {policy.get('n_layer', 8)}")
    print(f"  â€¢ n_cond_layers: {policy.get('n_cond_layers', 4)}")
    print(f"  â€¢ feature_dim: {bev_encoder.get('feature_dim', 256)}")
    print(f"  â€¢ æ˜¾å­˜: {resources['memory_percentage']}")
    print(f"  â€¢ é€Ÿåº¦: {resources['speed_relative']}")

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='ç»´åº¦é…ç½®æ£€æŸ¥å·¥å…·')
    parser.add_argument('--check', type=str, help='æ£€æŸ¥é…ç½®æ–‡ä»¶çš„å…¼å®¹æ€§')
    parser.add_argument('--compare', type=str, nargs=2, help='å¯¹æ¯”ä¸¤ä¸ªé…ç½®æ–‡ä»¶')
    parser.add_argument('--default', action='store_true', help='æ£€æŸ¥é»˜è®¤é…ç½®')
    
    args = parser.parse_args()
    
    if args.default:
        config_path = '/home/wang/Project/MoT-DP/config/nuscenes.yaml'
        print_compatibility_report(config_path)
    elif args.check:
        print_compatibility_report(args.check)
    elif args.compare:
        compare_configs(args.compare[0], args.compare[1])
    else:
        parser.print_help()
